{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AudioSet\n",
    "\n",
    "1. 在youtube对应的视频中抽取10秒的音频数据\n",
    "2. 对输入的音频，win_length = 25ms，hop_length = 10 ms，window = hann 进行STFT\n",
    "3. 使用64个Mel 刻度来计算Mel光谱图。覆盖范围125-7500赫兹\n",
    "4. 在 mel 频谱中，+.01的偏差（为了防止log(0))，进行对数计算\n",
    "5. 将这些特征加框成0.96秒的非重叠样本，其中每个样本包括64个MEL波段和每10ms一组的96帧（10msX96 = 0.96s），得到 96x64的mel fbank 特征\n",
    "6. 将 96x64 fbank 输入到 VGG 模型中\n",
    "7. 经过四组卷积/maxpool层，最后得到 128 的输出层\n",
    "8. 0.96s = 1s, 10秒的音频数据就有 10组 128 特征\n",
    "\n",
    "### 注：mel频谱计算请参看[mfcc-fbank](../mfcc-fbank/mfcc-fbank.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites:\n",
    "Please download the following files before you begin this tutorial:\n",
    "- [balanced_train_segments.csv](http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/balanced_train_segments.csv)\n",
    "- [unbalanced_train_segments.csv](http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/unbalanced_train_segments.csv)\n",
    "- [eval_segments.csv](http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/eval_segments.csv)\n",
    "- [128-dimension audio features](https://research.google.com/audioset/download.html) i.e., embeddings - About 2GB in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`examples` must contain YouTube IDs of all examples for one class. Consider the class `Clapping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63,/m/0l15bq,\"Clapping\"\r\n"
     ]
    }
   ],
   "source": [
    "!grep Clapping ../../audioset/class_labels_indices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_index = !grep Clapping ../../audioset/class_labels_indices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/m/0l15bq\n"
     ]
    }
   ],
   "source": [
    "print(class_label_index[0].split(\",\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0FMdORf5iGs, 30.000, 40.000, \"/m/04rlf,/m/081rb,/m/09x0r,/m/0l15bq\"\r\n",
      "1IxBagCJeZc, 150.000, 160.000, \"/m/01j3sz,/m/09x0r,/m/0l15bq\"\r\n",
      "1_DouJRW3PM, 30.000, 40.000, \"/m/028ght,/m/09x0r,/m/0l15bq\"\r\n",
      "2y9ikTsTsl0, 30.000, 40.000, \"/m/028ght,/m/09x0r,/m/0l15bq\"\r\n",
      "3PliaLqMSqg, 30.000, 40.000, \"/m/028ght,/m/09x0r,/m/0l15bq\"\r\n",
      "3ixOXsKUufM, 30.000, 40.000, \"/m/0l15bq\"\r\n",
      "4mOTOTJLv5U, 0.000, 10.000, \"/m/09x0r,/m/0l15bq,/m/0ytgt\"\r\n",
      "7Ep2a7_sbmc, 260.000, 270.000, \"/m/09x0r,/m/0l15bq\"\r\n",
      "7SpYywlGPyM, 30.000, 40.000, \"/m/09x0r,/m/0k65p,/m/0l15bq,/m/0ytgt\"\r\n",
      "AiGF0850kT8, 6.000, 16.000, \"/m/04rlf,/m/0l15bq\"\r\n"
     ]
    }
   ],
   "source": [
    "!grep /m/0l15bq ../../audioset/balanced_train_segments.csv |head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0FMdORf5iGs', '1IxBagCJeZc', '1_DouJRW3PM', '2y9ikTsTsl0']\n"
     ]
    }
   ],
   "source": [
    "examples = !grep /m/0l15bq ../../audioset/balanced_train_segments.csv | head -4 | cut -c -11\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_prefixes = set([i[:2] for i in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_filenames = [\"../../audioset/audioset_v1_embeddings/bal_train/\" + i + \".tfrecord\" for i in tfrecord_prefixes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "audio_embeddings_dict = {}\n",
    "audio_labels_dict = {}\n",
    "#all_tfrecord_filenames = glob.glob(\"bal_train/\" + example[:2] + \".tfrecord\")\n",
    "\n",
    "# Load embeddings\n",
    "sess = tf.Session() \n",
    "for tfrecord in tfrecord_filenames: \n",
    "  for example in tf.python_io.tf_record_iterator(tfrecord):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "    vid_id = tf_example.features.feature['video_id'].bytes_list.value[0].decode(encoding='UTF-8')\n",
    "    if vid_id in examples:\n",
    "      example_label = list(np.asarray(tf_example.features.feature['labels'].int64_list.value))\n",
    "      tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "      n_frames = len(tf_seq_example.feature_lists.feature_list['audio_embedding'].feature)\n",
    "      print(n_frames)\n",
    "      audio_frame = []\n",
    "      for i in range(n_frames):\n",
    "        audio_frame.append(tf.cast(tf.decode_raw(\n",
    "             tf_seq_example.feature_lists.feature_list['audio_embedding'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "            ,tf.float32).eval(session=sess))\n",
    "      audio_embeddings_dict[vid_id] = audio_frame\n",
    "      audio_labels_dict[vid_id] = example_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 每个数据，对应多个标签，其数值可以 class_labels_indices.csv中查到对应的含义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0FMdORf5iGs': [0, 63, 137, 387], '1_DouJRW3PM': [0, 63, 67], '1IxBagCJeZc': [0, 16, 63], '2y9ikTsTsl0': [0, 63, 67]}\n"
     ]
    }
   ],
   "source": [
    "print(audio_labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其数据是1秒1帧，共10秒，所以是10帧的128D特征，（10，128）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "feature = np.array(audio_embeddings_dict['0FMdORf5iGs'])\n",
    "\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
